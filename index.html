---
layout: page
title: Guanhong Wang
subtitle: Phd Student @Zhejiang University
use-site-title: false
---

<head>
	<style>
		a { text-decoration : none; }
		a:hover { text-decoration : underline; }
		a, a:visited { color : #b5194f; }
	</style>
	<script src="https://kit.fontawesome.com/5bef57b3e9.js" crossorigin="anonymous"></script>
</head>

<br>
Guanhong Wang is a Phd student at Zhejiang University, with <a href="https://cvnext.github.io/">CVNext Lab</a> advised by Prof. <a href="https://person.zju.edu.cn/en/gaoangwang/">Gaoang Wang</a>. His research interests include video understanding, multi-modality learning and vision and language.

<br>
<br>
<hr style="height:2px;border-width:0;color:gray;background-color:gray">
<b><i class="fa-regular fa-note-sticky" style="font-size:24px"></i> Selected Publications:</b>
<p><font color="grey" size="3">
Also see <a href="https://rejoicelf.github.io/publications" target="_blank">Publications Page</a> and <a href="https://scholar.google.com/citations?user=bMaDL2EAAAAJ&hl=en" target="_blank">Google Scholar</a>.
</font></p>

<ul>
	<li>
		<p style="font-size:16px"> 
		    	<strong>
		    	MovieChat: From Dense Token to Sparse Memory in Long Video Understanding
		    	</strong>
		    	<br>
		    	Enxin Song*, Wenhao Chai*♡, <b>Guanhong Wang*</b>,Yucheng Zhang, Haoyang Zhou, Feiyang Wu, Tian Ye, Jenq-Neng Hwang, Gaoang Wang✉
		    	<br>
		    	<em>arXiv Preprint.</em>
		    	<br>
		    	<a href="https://rese1f.github.io/MovieChat/">[Website]</a>
		   	<a href="https://arxiv.org/abs/2307.16449">[Paper]</a>
		    	<a href="https://github.com/rese1f/MovieChat">[Dataset]</a>
		    	<a href="https://github.com/rese1f/MovieChat">[Code]</a>
		    	<img alt="NPM" src="https://img.shields.io/github/stars/rese1f/MovieChat?style=social">
		    	<br>
		    	<font color="grey" size="2">
		    	MovieChat achieves state-of-the-art performace in long video understanding by introducing memory mechanism.
		    	</font>
		</p>
	</li>
<!-- 	<li>
		<p style="font-size:16px"> 
			<strong>
			StableVideo: Text-driven Consistency-aware Diffusion Video Editing
			</strong>
			<br>
			<b>Wenhao Chai</b>, Xun Guo, Gaoang Wang, Yan Lu✉
			<br>
			<font color="#E89B00">
			<em>International Conference on Computer Vision (ICCV), 2023</em>
			</font>
			<br>
			<font color="grey" size="2">
			We tackle introduce temporal dependency to existing text-driven diffusion models, which allows them to generate consistent appearance for the new objects.
			</font>
		</p>
	</li> -->
<!-- 	<li>
		<p style="font-size:16px"> 
			<strong>
			Global Adaptation meets Local Generalization: Unsupervised Domain Adaptation for 3D Human Pose Estimation
			</strong>
			<br>
			<b>Wenhao Chai</b>, Zhongyu Jiang, Jenq-Neng Hwang, Gaoang Wang✉
			<br>
			<font color="#E89B00">
			<em>International Conference on Computer Vision (ICCV), 2023</em>
			</font>
			<br>
			<a href="https://arxiv.org/abs/2303.16456">[Paper]</a>
			<a href="https://github.com/rese1f/PoseDA">[Code]</a>
			<img alt="NPM" src="https://img.shields.io/github/stars/rese1f/PoseDA?style=social">
			<br>
			<font color="grey" size="2">
			A simple yet effective framework of unsupervised domain adaptation for 3D human pose estimation.
			</font>
	  	</p>
	</li> -->
	
</ul>

<hr style="height:2px;border-width:0;color:gray;background-color:gray">
<b><i class="fa-solid fa-pen-to-square" style="font-size:24px"></i> Updates:</b><br><br>

<ul>
	<li><i>July 2023:</i> <i class="fa-regular fa-copy" style="font-size:20px"></i> Our project <i>MovieChat: From Dense Token to Sparse Memory in Long Video Understanding</i> is released at <a href="https://rese1f.github.io/MovieChat/">website</a>.
	</li><br>

	<li><i>March 2022:</i> <i class="fa-regular fa-note-sticky" style="font-size:20px"></i> Our paper <i>Human-centered Prior-guided and Task-dependent Multi-task Representation Learning for Action Recognition Pre-training</i> accepted by ICME 2022.
	</li><br>

	<li><i>Oct 2021:</i> Attend <a href="http://valser.org/2021/#/">VALSE 2021</a> in Hangzhou.</a>.
	</li><br>
	
	<li><i>June 2021:</i> Start my Phd research on Video Action Recognition task, advised by Professor <a href="https://person.zju.edu.cn/en/gaoangwang/">Gaoang Wang</a>.
	</li><br>

</ul>
